{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b15c815",
   "metadata": {},
   "source": [
    "# Testing Recommender Functions\n",
    "\n",
    "This notebook installs the required dependencies and tests the recommender functions defined in your modules (e.g. `utils.py` and `recommender.py`). It loads the models via the `get_models()` function and then tests various ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install numpy scikit-learn tensorflow keras fastapi torch transformers\n",
    "\n",
    "# If your project has a requirements.txt file, you can also use:\n",
    "# !pip install --no-cache-dir -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c8c7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 01:38:36.851472: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-03 01:38:36.953835: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740958717.015654   89636 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740958717.036531   89636 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-03 01:38:37.149435: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to /home/t/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/t/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "from utils import get_models  # Ensure these are in your PYTHONPATH\n",
    "from recommender import ensemble_bagging, ensemble_boosting, train_stacking_meta_model, ensemble_stacking, hybrid_ensemble, tokenize_input\n",
    "\n",
    "# For demonstration, we assume get_models() returns a dictionary of models for clusters 0, 1, 2, etc.\n",
    "print(\"Modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f8ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Loaded news data:\n",
      "   NewsID   Category               SubCategory  \\\n",
      "0  N88753  lifestyle           lifestyleroyals   \n",
      "1  N45436       news  newsscienceandtechnology   \n",
      "2  N23144     health                weightloss   \n",
      "3  N86255     health                   medical   \n",
      "4  N93187       news                 newsworld   \n",
      "\n",
      "                                               Title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1    Walmart Slashes Prices on Last-Generation iPads   \n",
      "2                      50 Worst Habits For Belly Fat   \n",
      "3  Dispose of unwanted prescription drugs during ...   \n",
      "4  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "\n",
      "                                            Abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  Apple's new iPad releases bring big deals on l...   \n",
      "2  These seemingly harmless habits are holding yo...   \n",
      "3                                                NaN   \n",
      "4  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "\n",
      "                                             URL  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
      "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "3  https://assets.msn.com/labs/mind/AAISxPN.html   \n",
      "4  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "\n",
      "                                       TitleEntities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "3  [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
      "4                                                 []   \n",
      "\n",
      "                                    AbstractEntities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...  \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "3                                                 []  \n",
      "4  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "\n",
      "Loaded behaviors data:\n",
      "   ImpressionID   UserID                    Time  \\\n",
      "0             1   U87243  11/10/2019 11:30:54 AM   \n",
      "1             2  U598644   11/12/2019 1:45:29 PM   \n",
      "2             3  U532401  11/13/2019 11:23:03 AM   \n",
      "3             4  U593596  11/12/2019 12:24:09 PM   \n",
      "4             5  U239687   11/14/2019 8:03:01 PM   \n",
      "\n",
      "                                         HistoryText  \\\n",
      "0  N8668 N39081 N65259 N79529 N73408 N43615 N2937...   \n",
      "1  N56056 N8726 N70353 N67998 N83823 N111108 N107...   \n",
      "2  N128643 N87446 N122948 N9375 N82348 N129412 N5...   \n",
      "3  N31043 N39592 N4104 N8223 N114581 N92747 N1207...   \n",
      "4  N65250 N122359 N71723 N53796 N41663 N41484 N11...   \n",
      "\n",
      "                                         Impressions  \n",
      "0  N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...  \n",
      "1  N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...  \n",
      "2              N103852-0 N53474-0 N127836-0 N47925-1  \n",
      "3  N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...  \n",
      "4  N76209-0 N48841-0 N67937-0 N62235-0 N6307-0 N3...  \n",
      "Number of columns in user_category_profiles: 18\n",
      "Number of unique users in behaviors_df: 711222\n",
      "Number of unique users in behaviors_df: 711222\n",
      "Number of users in user_category_profiles: 711222\n",
      "Number of missing UserIDs in user_category_profiles: 0\n",
      "Cluster 0: 44551 training samples, 11138 validation samples.\n",
      "Cluster 1: 48725 training samples, 12182 validation samples.\n",
      "Cluster 2: 53212 training samples, 13304 validation samples.\n",
      "\n",
      "Loading model for Cluster 0 from fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "user_category_profiles.pkl\n",
      "gdrive.py\n",
      "tokenizer.pkl\n",
      "utils.py\n",
      "Dockerfile\n",
      "fastapi copy.py\n",
      "recommender.py\n",
      "models.py\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_model.py\n",
      "backend.py\n",
      "test_recommender.ipynb\n",
      "fastapi2.py\n",
      "models\n",
      "test_recommender.py\n",
      ".ipynb_checkpoints\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "dataset\n",
      "backend-flask-unused.py\n",
      "fastformer.json\n",
      "requirements.txt\n",
      "backend copy 2.py\n",
      "recommender-Copy1.py\n",
      ".cache\n",
      "backend copy.py\n",
      "__pycache__\n",
      "upload_to_hf.py\n",
      "2.18.0\n",
      "3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1740958918.503480   89636 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9517 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "I0000 00:00:1740958918.507005   89636 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5660 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:05:00.0, compute capability: 8.6\n",
      "/home/t/tf/lib/python3.10/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'user_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/t/tf/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 46 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model for Cluster 1 from fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "user_category_profiles.pkl\n",
      "gdrive.py\n",
      "tokenizer.pkl\n",
      "utils.py\n",
      "Dockerfile\n",
      "fastapi copy.py\n",
      "recommender.py\n",
      "models.py\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_model.py\n",
      "backend.py\n",
      "test_recommender.ipynb\n",
      "fastapi2.py\n",
      "models\n",
      "test_recommender.py\n",
      ".ipynb_checkpoints\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "dataset\n",
      "backend-flask-unused.py\n",
      "fastformer.json\n",
      "requirements.txt\n",
      "backend copy 2.py\n",
      "recommender-Copy1.py\n",
      ".cache\n",
      "backend copy.py\n",
      "__pycache__\n",
      "upload_to_hf.py\n",
      "2.18.0\n",
      "3.8.0\n",
      "\n",
      "Loading model for Cluster 2 from fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "user_category_profiles.pkl\n",
      "gdrive.py\n",
      "fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      "tokenizer.pkl\n",
      "utils.py\n",
      "Dockerfile\n",
      "fastapi copy.py\n",
      "recommender.py\n",
      "models.py\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_model.py\n",
      "backend.py\n",
      "test_recommender.ipynb\n",
      "fastapi2.py\n",
      "models\n",
      "test_recommender.py\n",
      ".ipynb_checkpoints\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "dataset\n",
      "backend-flask-unused.py\n",
      "fastformer.json\n",
      "requirements.txt\n",
      "backend copy 2.py\n",
      "recommender-Copy1.py\n",
      ".cache\n",
      "backend copy.py\n",
      "__pycache__\n",
      "upload_to_hf.py\n",
      "2.18.0\n",
      "3.8.0\n",
      "Returning models list\n",
      "{0: <Functional name=functional, built=True>, 1: <Functional name=functional_1, built=True>, 2: <Functional name=functional_2, built=True>}\n",
      "Models loaded: dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer \"functional\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(1, 2) dtype=int64>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m test_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a dummy test input for the recommender functions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Test ensemble bagging\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m bagging_pred \u001b[38;5;241m=\u001b[39m \u001b[43mensemble_bagging\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble Bagging Prediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m, bagging_pred)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Test ensemble boosting with dummy error values\u001b[39;00m\n",
      "File \u001b[0;32m~/24-11-9/news/new/news/mirror/newest-version/news/backend/recommender.py:27\u001b[0m, in \u001b[0;36mensemble_bagging\u001b[0;34m(input_text, models)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mensemble_bagging\u001b[39m(input_text: \u001b[38;5;28mstr\u001b[39m, models: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m---> 27\u001b[0m     y1 \u001b[38;5;241m=\u001b[39m \u001b[43mfastformer_model1_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     y2 \u001b[38;5;241m=\u001b[39m fastformer_model2_predict(input_text, models[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     29\u001b[0m     y3 \u001b[38;5;241m=\u001b[39m fastformer_model3_predict(input_text, models[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/24-11-9/news/new/news/mirror/newest-version/news/backend/recommender.py:13\u001b[0m, in \u001b[0;36mfastformer_model1_predict\u001b[0;34m(input_text, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfastformer_model1_predict\u001b[39m(input_text: \u001b[38;5;28mstr\u001b[39m, model):\n\u001b[1;32m     12\u001b[0m     input_arr \u001b[38;5;241m=\u001b[39m tokenize_input(input_text)\n\u001b[0;32m---> 13\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/tf/lib/python3.10/site-packages/keras/src/layers/input_spec.py:160\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Layer \"functional\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(1, 2) dtype=int64>]"
     ]
    }
   ],
   "source": [
    "# Load ensemble models using the get_models function\n",
    "print(\"Loading models...\")\n",
    "models_dict = get_models()\n",
    "print(\"Models loaded:\", models_dict.keys())\n",
    "\n",
    "# Define a test input text for recommendation\n",
    "test_input = \"This is a dummy test input for the recommender functions.\"\n",
    "\n",
    "# Test ensemble bagging\n",
    "bagging_pred = ensemble_bagging(test_input, models_dict)\n",
    "print(\"Ensemble Bagging Prediction:\", bagging_pred)\n",
    "\n",
    "# Test ensemble boosting with dummy error values\n",
    "dummy_errors = np.array([0.2, 0.15, 0.25])\n",
    "boosting_pred = ensemble_boosting(test_input, models_dict, dummy_errors)\n",
    "print(\"Ensemble Boosting Prediction:\", boosting_pred)\n",
    "\n",
    "# Test ensemble stacking with dummy training data\n",
    "X_train_dummy = np.array([\n",
    "    [0.80, 0.75, 0.85],\n",
    "    [0.55, 0.60, 0.50],\n",
    "    [0.30, 0.35, 0.25],\n",
    "    [0.20, 0.25, 0.15]\n",
    "])\n",
    "y_train_dummy = np.array([1, 0, 1, 0])\n",
    "meta_model = train_stacking_meta_model(X_train_dummy, y_train_dummy)\n",
    "stacking_pred = ensemble_stacking(test_input, models_dict, meta_model)\n",
    "print(\"Ensemble Stacking Prediction:\", stacking_pred)\n",
    "\n",
    "# Test hybrid ensemble\n",
    "hybrid_pred = hybrid_ensemble(test_input, models_dict, dummy_errors, meta_model)\n",
    "print(\"Hybrid Ensemble Prediction:\", hybrid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2e6a8",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "You can now develop and test your recommendation functions independently of the FastAPI backend. \n",
    "\n",
    "For further debugging, you might want to add additional print statements or assertions within your recommender functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
