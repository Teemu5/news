{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b15c815",
   "metadata": {},
   "source": [
    "# Testing Recommender Functions\n",
    "\n",
    "This notebook installs the required dependencies and tests the recommender functions defined in your modules (e.g. `utils.py` and `recommender.py`). It loads the models via the `get_models()` function and then tests various ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install numpy scikit-learn tensorflow keras fastapi torch transformers\n",
    "\n",
    "# If your project has a requirements.txt file, you can also use:\n",
    "# !pip install --no-cache-dir -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "from utils import get_models, tokenize_input  # Ensure these are in your PYTHONPATH\n",
    "from recommender import ensemble_bagging, ensemble_boosting, train_stacking_meta_model, ensemble_stacking, hybrid_ensemble\n",
    "\n",
    "# For demonstration, we assume get_models() returns a dictionary of models for clusters 0, 1, 2, etc.\n",
    "print(\"Modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ensemble models using the get_models function\n",
    "print(\"Loading models...\")\n",
    "models_dict = get_models()\n",
    "print(\"Models loaded:\", models_dict.keys())\n",
    "\n",
    "# Define a test input text for recommendation\n",
    "test_input = \"This is a dummy test input for the recommender functions.\"\n",
    "\n",
    "# Test ensemble bagging\n",
    "bagging_pred = ensemble_bagging(test_input, models_dict)\n",
    "print(\"Ensemble Bagging Prediction:\", bagging_pred)\n",
    "\n",
    "# Test ensemble boosting with dummy error values\n",
    "dummy_errors = np.array([0.2, 0.15, 0.25])\n",
    "boosting_pred = ensemble_boosting(test_input, models_dict, dummy_errors)\n",
    "print(\"Ensemble Boosting Prediction:\", boosting_pred)\n",
    "\n",
    "# Test ensemble stacking with dummy training data\n",
    "X_train_dummy = np.array([\n",
    "    [0.80, 0.75, 0.85],\n",
    "    [0.55, 0.60, 0.50],\n",
    "    [0.30, 0.35, 0.25],\n",
    "    [0.20, 0.25, 0.15]\n",
    "])\n",
    "y_train_dummy = np.array([1, 0, 1, 0])\n",
    "meta_model = train_stacking_meta_model(X_train_dummy, y_train_dummy)\n",
    "stacking_pred = ensemble_stacking(test_input, models_dict, meta_model)\n",
    "print(\"Ensemble Stacking Prediction:\", stacking_pred)\n",
    "\n",
    "# Test hybrid ensemble\n",
    "hybrid_pred = hybrid_ensemble(test_input, models_dict, dummy_errors, meta_model)\n",
    "print(\"Hybrid Ensemble Prediction:\", hybrid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2e6a8",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "You can now develop and test your recommendation functions independently of the FastAPI backend. \n",
    "\n",
    "For further debugging, you might want to add additional print statements or assertions within your recommender functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
