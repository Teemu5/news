{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b15c815",
   "metadata": {},
   "source": [
    "# Testing Recommender Functions\n",
    "\n",
    "This notebook installs the required dependencies and tests the recommender functions defined in your modules (e.g. `utils.py` and `recommender.py`). It loads the models via the `get_models()` function and then tests various ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "#!pip install --upgrade pip\n",
    "#!pip install numpy scikit-learn tensorflow keras fastapi torch transformers\n",
    "\n",
    "# If your project has a requirements.txt file, you can also use:\n",
    "# !pip install --no-cache-dir -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c8c7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 13:55:39.755834: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 13:55:39.821568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741182939.854646    3586 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741182939.861986    3586 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 13:55:39.915407: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "from utils import get_models  # Ensure these are in your PYTHONPATH\n",
    "from recommender import ensemble_bagging, ensemble_boosting, train_stacking_meta_model, ensemble_stacking, hybrid_ensemble, tokenize_input\n",
    "\n",
    "# For demonstration, we assume get_models() returns a dictionary of models for clusters 0, 1, 2, etc.\n",
    "print(\"Modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb7c730-e9d6-4a9f-b541-9c779858a1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History tensor shape: (1, 50, 30)\n",
      "Candidate tensor shape: (1, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 13:56:00.307815: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f8ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Loaded news data:\n",
      "   NewsID   Category               SubCategory  \\\n",
      "0  N88753  lifestyle           lifestyleroyals   \n",
      "1  N45436       news  newsscienceandtechnology   \n",
      "2  N23144     health                weightloss   \n",
      "3  N86255     health                   medical   \n",
      "4  N93187       news                 newsworld   \n",
      "\n",
      "                                               Title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1    Walmart Slashes Prices on Last-Generation iPads   \n",
      "2                      50 Worst Habits For Belly Fat   \n",
      "3  Dispose of unwanted prescription drugs during ...   \n",
      "4  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "\n",
      "                                            Abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  Apple's new iPad releases bring big deals on l...   \n",
      "2  These seemingly harmless habits are holding yo...   \n",
      "3                                                NaN   \n",
      "4  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "\n",
      "                                             URL  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
      "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "3  https://assets.msn.com/labs/mind/AAISxPN.html   \n",
      "4  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "\n",
      "                                       TitleEntities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "3  [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
      "4                                                 []   \n",
      "\n",
      "                                    AbstractEntities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...  \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "3                                                 []  \n",
      "4  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "\n",
      "Loaded behaviors data:\n",
      "   ImpressionID   UserID                    Time  \\\n",
      "0             1   U87243  11/10/2019 11:30:54 AM   \n",
      "1             2  U598644   11/12/2019 1:45:29 PM   \n",
      "2             3  U532401  11/13/2019 11:23:03 AM   \n",
      "3             4  U593596  11/12/2019 12:24:09 PM   \n",
      "4             5  U239687   11/14/2019 8:03:01 PM   \n",
      "\n",
      "                                         HistoryText  \\\n",
      "0  N8668 N39081 N65259 N79529 N73408 N43615 N2937...   \n",
      "1  N56056 N8726 N70353 N67998 N83823 N111108 N107...   \n",
      "2  N128643 N87446 N122948 N9375 N82348 N129412 N5...   \n",
      "3  N31043 N39592 N4104 N8223 N114581 N92747 N1207...   \n",
      "4  N65250 N122359 N71723 N53796 N41663 N41484 N11...   \n",
      "\n",
      "                                         Impressions  \n",
      "0  N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...  \n",
      "1  N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...  \n",
      "2              N103852-0 N53474-0 N127836-0 N47925-1  \n",
      "3  N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...  \n",
      "4  N76209-0 N48841-0 N67937-0 N62235-0 N6307-0 N3...  \n",
      "Number of columns in user_category_profiles: 18\n",
      "Number of unique users in behaviors_df: 711222\n",
      "Number of unique users in behaviors_df: 711222\n",
      "Number of users in user_category_profiles: 711222\n",
      "Number of missing UserIDs in user_category_profiles: 0\n",
      "Cluster 0: 44551 training samples, 11138 validation samples.\n",
      "Cluster 1: 48725 training samples, 12182 validation samples.\n",
      "Cluster 2: 53212 training samples, 13304 validation samples.\n",
      "\n",
      "Loading model for Cluster 0 from fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      ".cache\n",
      ".ipynb_checkpoints\n",
      "backend copy 2.py\n",
      "backend copy.py\n",
      "backend-flask-unused.py\n",
      "backend.py\n",
      "data\n",
      "dataset\n",
      "Dockerfile\n",
      "downloads\n",
      "fastapi copy.py\n",
      "fastapi2.py\n",
      "fastformer.json\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_cluster_0_full_balanced_1_epoch.h5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.hdf5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.json\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_0_full_balanced_1_epoch.weights.h5\n",
      "fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      "fastformer_model.py\n",
      "gdrive.py\n",
      "models\n",
      "models.py\n",
      "recommender.py\n",
      "requirements.txt\n",
      "test_recommender.ipynb\n",
      "test_recommender.py\n",
      "tokenizer.pkl\n",
      "upload_to_hf.py\n",
      "user_category_profiles.pkl\n",
      "utils.py\n",
      "__pycache__\n",
      "2.18.0\n",
      "3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'user_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 46 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model for Cluster 1 from fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      ".cache\n",
      ".ipynb_checkpoints\n",
      "backend copy 2.py\n",
      "backend copy.py\n",
      "backend-flask-unused.py\n",
      "backend.py\n",
      "data\n",
      "dataset\n",
      "Dockerfile\n",
      "downloads\n",
      "fastapi copy.py\n",
      "fastapi2.py\n",
      "fastformer.json\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_cluster_0_full_balanced_1_epoch.h5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.hdf5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.json\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_0_full_balanced_1_epoch.weights.h5\n",
      "fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      "fastformer_model.py\n",
      "gdrive.py\n",
      "models\n",
      "models.py\n",
      "recommender.py\n",
      "requirements.txt\n",
      "test_recommender.ipynb\n",
      "test_recommender.py\n",
      "tokenizer.pkl\n",
      "upload_to_hf.py\n",
      "user_category_profiles.pkl\n",
      "utils.py\n",
      "__pycache__\n",
      "2.18.0\n",
      "3.8.0\n",
      "\n",
      "Loading model for Cluster 2 from fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      ".cache\n",
      ".ipynb_checkpoints\n",
      "backend copy 2.py\n",
      "backend copy.py\n",
      "backend-flask-unused.py\n",
      "backend.py\n",
      "data\n",
      "dataset\n",
      "Dockerfile\n",
      "downloads\n",
      "fastapi copy.py\n",
      "fastapi2.py\n",
      "fastformer.json\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_cluster_0_full_balanced_1_epoch.h5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.hdf5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.json\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_0_full_balanced_1_epoch.weights.h5\n",
      "fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      "fastformer_model.py\n",
      "gdrive.py\n",
      "models\n",
      "models.py\n",
      "recommender.py\n",
      "requirements.txt\n",
      "test_recommender.ipynb\n",
      "test_recommender.py\n",
      "tokenizer.pkl\n",
      "upload_to_hf.py\n",
      "user_category_profiles.pkl\n",
      "utils.py\n",
      "__pycache__\n",
      "2.18.0\n",
      "3.8.0\n",
      "Returning models list\n",
      "{0: <Functional name=functional, built=True>, 1: <Functional name=functional_1, built=True>, 2: <Functional name=functional_2, built=True>}\n",
      "Models loaded: dict_keys([0, 1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741183042.339769    3726 service.cc:148] XLA service 0x7fbd2800a430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741183042.340942    3726 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
      "2025-03-05 13:57:22.603298: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741183045.569925    3726 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Ensemble Bagging Prediction: [0.5459661]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Ensemble Boosting Prediction: [0.55218655]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Ensemble Stacking Prediction: [0.50922481]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Hybrid Ensemble Prediction: [0.53579248]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "# Remap standalone keras modules to tensorflow.keras\n",
    "sys.modules[\"keras.preprocessing.text\"] = tf.keras.preprocessing.text\n",
    "sys.modules[\"keras.preprocessing.sequence\"] = tf.keras.preprocessing.sequence\n",
    "sys.modules[\"keras.utils\"] = tf.keras.utils\n",
    "\n",
    "news_file = \"news.tsv\"\n",
    "behaviors_file = \"behaviors.tsv\"\n",
    "data_dir = 'dataset/train/'  # Adjust path as necessary\n",
    "valid_data_dir = 'dataset/valid/'  # Adjust path as necessary\n",
    "news_path = os.path.join(data_dir, news_file)\n",
    "behaviors_path = os.path.join(data_dir, behaviors_file)\n",
    "\n",
    "# Set maximum lengths (should match your model settings)\n",
    "max_history_length = 50\n",
    "max_title_length = 30\n",
    "\n",
    "# Load the pre-saved tokenizer (assumes you already created and saved it)\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Load MIND test data (adjust file paths as necessary)\n",
    "# Assume news.tsv contains columns: NewsID, Category, SubCategory, Title, Abstract, URL, TitleEntities, AbstractEntities\n",
    "news_df = pd.read_csv(news_path, sep='\\t', \n",
    "                      names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])\n",
    "# Assume behaviors_test.tsv contains: ImpressionID, UserID, Time, HistoryText, Impressions\n",
    "behaviors_df = pd.read_csv(behaviors_path, sep='\\t', \n",
    "                           names=['ImpressionID', 'UserID', 'Time', 'HistoryText', 'Impressions'])\n",
    "\n",
    "# Create a dictionary mapping NewsID to Title (or CombinedText if available)\n",
    "news_dict = dict(zip(news_df['NewsID'], news_df['Title']))\n",
    "\n",
    "# Select one sample from the test behaviors\n",
    "sample = behaviors_df.iloc[0]\n",
    "\n",
    "# Process history: split the HistoryText (a space-separated string of NewsIDs)\n",
    "history_text = sample['HistoryText']\n",
    "history_ids = history_text.split() if pd.notna(history_text) else []\n",
    "\n",
    "# Retrieve the title for each news ID in the history (default to empty string if missing)\n",
    "history_titles = [news_dict.get(nid, \"\") for nid in history_ids]\n",
    "\n",
    "# Convert history titles to sequences using the tokenizer\n",
    "history_sequences = tokenizer.texts_to_sequences(history_titles)\n",
    "# Pad each sequence to max_title_length\n",
    "history_padded = pad_sequences(history_sequences, maxlen=max_title_length, \n",
    "                               padding='post', truncating='post', value=0)\n",
    "\n",
    "# Ensure the history has exactly max_history_length rows:\n",
    "if history_padded.shape[0] < max_history_length:\n",
    "    # Pre-pad with zeros if there are fewer history items\n",
    "    pad_rows = np.zeros((max_history_length - history_padded.shape[0], max_title_length), dtype=int)\n",
    "    history_padded = np.vstack([pad_rows, history_padded])\n",
    "else:\n",
    "    # If too many, take the last max_history_length items\n",
    "    history_padded = history_padded[-max_history_length:]\n",
    "\n",
    "# Process candidate: the \"Impressions\" column is a space-separated list like \"newsID-label newsID-label ...\"\n",
    "impressions = sample['Impressions']\n",
    "first_candidate = impressions.split()[0]  # take the first candidate\n",
    "candidate_news_id = first_candidate.split('-')[0]\n",
    "candidate_title = news_dict.get(candidate_news_id, \"\")\n",
    "candidate_sequence = tokenizer.texts_to_sequences([candidate_title])\n",
    "candidate_padded = pad_sequences(candidate_sequence, maxlen=max_title_length, \n",
    "                                 padding='post', truncating='post', value=0)[0]\n",
    "\n",
    "# Convert to TensorFlow tensors\n",
    "history_tensor = tf.convert_to_tensor([history_padded], dtype=tf.int32)  # shape: (1, max_history_length, max_title_length)\n",
    "candidate_tensor = tf.convert_to_tensor([candidate_padded], dtype=tf.int32)  # shape: (1, max_title_length)\n",
    "\n",
    "print(\"History tensor shape:\", history_tensor.shape)\n",
    "print(\"Candidate tensor shape:\", candidate_tensor.shape)\n",
    "\n",
    "# Load ensemble models using the get_models function\n",
    "print(\"Loading models...\")\n",
    "models_dict = get_models()\n",
    "print(\"Models loaded:\", models_dict.keys())\n",
    "\n",
    "# Test ensemble bagging\n",
    "bagging_pred = ensemble_bagging(history_tensor, candidate_tensor, models_dict)\n",
    "print(\"Ensemble Bagging Prediction:\", bagging_pred)\n",
    "\n",
    "# Test ensemble boosting with dummy error values\n",
    "dummy_errors = np.array([0.2, 0.15, 0.25])\n",
    "boosting_pred = ensemble_boosting(history_tensor, candidate_tensor, models_dict, dummy_errors)\n",
    "print(\"Ensemble Boosting Prediction:\", boosting_pred)\n",
    "\n",
    "# Test ensemble stacking with dummy training data\n",
    "X_train_dummy = np.array([\n",
    "    [0.80, 0.75, 0.85],\n",
    "    [0.55, 0.60, 0.50],\n",
    "    [0.30, 0.35, 0.25],\n",
    "    [0.20, 0.25, 0.15]\n",
    "])\n",
    "y_train_dummy = np.array([1, 0, 1, 0])\n",
    "meta_model = train_stacking_meta_model(X_train_dummy, y_train_dummy)\n",
    "stacking_pred = ensemble_stacking(history_tensor, candidate_tensor, models_dict, meta_model)\n",
    "print(\"Ensemble Stacking Prediction:\", stacking_pred)\n",
    "\n",
    "# Test hybrid ensemble\n",
    "hybrid_pred = hybrid_ensemble(history_tensor, candidate_tensor, models_dict, dummy_errors, meta_model)\n",
    "print(\"Hybrid Ensemble Prediction:\", hybrid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2e6a8",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "You can now develop and test your recommendation functions independently of the FastAPI backend. \n",
    "\n",
    "For further debugging, you might want to add additional print statements or assertions within your recommender functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
