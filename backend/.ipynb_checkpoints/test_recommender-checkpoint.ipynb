{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b15c815",
   "metadata": {},
   "source": [
    "# Testing Recommender Functions\n",
    "\n",
    "This notebook installs the required dependencies and tests the recommender functions defined in your modules (e.g. `utils.py` and `recommender.py`). It loads the models via the `get_models()` function and then tests various ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d1e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "#!pip install --upgrade pip\n",
    "#!pip install numpy scikit-learn tensorflow keras fastapi torch transformers\n",
    "\n",
    "# If your project has a requirements.txt file, you can also use:\n",
    "# !pip install --no-cache-dir -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65841aec-a0d5-4a5b-83dc-b3c7ab29595d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 23:57:17.127063: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-23 23:57:17.162306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742774237.187198   64037 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742774237.194479   64037 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-23 23:57:17.234173: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded news data:\n",
      "   NewsID   Category               SubCategory  \\\n",
      "0  N88753  lifestyle           lifestyleroyals   \n",
      "1  N45436       news  newsscienceandtechnology   \n",
      "2  N23144     health                weightloss   \n",
      "3  N86255     health                   medical   \n",
      "4  N93187       news                 newsworld   \n",
      "\n",
      "                                               Title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1    Walmart Slashes Prices on Last-Generation iPads   \n",
      "2                      50 Worst Habits For Belly Fat   \n",
      "3  Dispose of unwanted prescription drugs during ...   \n",
      "4  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "\n",
      "                                            Abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  Apple's new iPad releases bring big deals on l...   \n",
      "2  These seemingly harmless habits are holding yo...   \n",
      "3                                                NaN   \n",
      "4  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "\n",
      "                                             URL  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
      "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "3  https://assets.msn.com/labs/mind/AAISxPN.html   \n",
      "4  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "\n",
      "                                       TitleEntities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "3  [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
      "4                                                 []   \n",
      "\n",
      "                                    AbstractEntities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...  \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "3                                                 []  \n",
      "4  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "\n",
      "Loaded behaviors data:\n",
      "   ImpressionID   UserID                    Time  \\\n",
      "0             1   U87243  11/10/2019 11:30:54 AM   \n",
      "1             2  U598644   11/12/2019 1:45:29 PM   \n",
      "2             3  U532401  11/13/2019 11:23:03 AM   \n",
      "3             4  U593596  11/12/2019 12:24:09 PM   \n",
      "4             5  U239687   11/14/2019 8:03:01 PM   \n",
      "\n",
      "                                         HistoryText  \\\n",
      "0  N8668 N39081 N65259 N79529 N73408 N43615 N2937...   \n",
      "1  N56056 N8726 N70353 N67998 N83823 N111108 N107...   \n",
      "2  N128643 N87446 N122948 N9375 N82348 N129412 N5...   \n",
      "3  N31043 N39592 N4104 N8223 N114581 N92747 N1207...   \n",
      "4  N65250 N122359 N71723 N53796 N41663 N41484 N11...   \n",
      "\n",
      "                                         Impressions  \n",
      "0  N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...  \n",
      "1  N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...  \n",
      "2              N103852-0 N53474-0 N127836-0 N47925-1  \n",
      "3  N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...  \n",
      "4  N76209-0 N48841-0 N67937-0 N62235-0 N6307-0 N3...  \n",
      "Number of columns in user_category_profiles: 18\n",
      "Number of unique users in behaviors_df: 711222\n",
      "Number of unique users in behaviors_df: 711222\n",
      "Number of users in user_category_profiles: 711222\n",
      "Number of missing UserIDs in user_category_profiles: 0\n",
      "Cluster 0: 44551 training samples, 11138 validation samples.\n",
      "Cluster 1: 48725 training samples, 12182 validation samples.\n",
      "Cluster 2: 53212 training samples, 13304 validation samples.\n",
      "\n",
      "Loading model for Cluster 0 from fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      ".cache\n",
      ".ipynb_checkpoints\n",
      ".Trash-0\n",
      "backend copy 2.py\n",
      "backend copy.py\n",
      "backend-flask-unused.py\n",
      "backend.py\n",
      "data\n",
      "dataset\n",
      "detailed_log.log\n",
      "Dockerfile\n",
      "downloads\n",
      "experiment_results.csv\n",
      "fastapi copy.py\n",
      "fastapi2.py\n",
      "fastformer.json\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_cluster_0_full_balanced_1_epoch.h5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.json\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_0_full_balanced_1_epoch.weights.h5\n",
      "fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      "fastformer_model.py\n",
      "gdrive.py\n",
      "models\n",
      "models.py\n",
      "my_log.py\n",
      "recommender.py\n",
      "requirements.txt\n",
      "results\n",
      "results.csv\n",
      "stage1_candidates.csv\n",
      "test_recommender.ipynb\n",
      "test_recommender.py\n",
      "tfidf_clicked_articles.csv\n",
      "tokenizer.pkl\n",
      "upload_to_hf.py\n",
      "user_category_profiles.pkl\n",
      "utils copy.py\n",
      "utils.py\n",
      "__pycache__\n",
      "2.18.0\n",
      "3.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 23:58:28.708046: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/usr/local/lib/python3.11/site-packages/keras/src/layers/layer.py:393: UserWarning: `build()` was called on layer 'user_encoder', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 46 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model for Cluster 1 from fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      ".cache\n",
      ".ipynb_checkpoints\n",
      ".Trash-0\n",
      "backend copy 2.py\n",
      "backend copy.py\n",
      "backend-flask-unused.py\n",
      "backend.py\n",
      "data\n",
      "dataset\n",
      "detailed_log.log\n",
      "Dockerfile\n",
      "downloads\n",
      "experiment_results.csv\n",
      "fastapi copy.py\n",
      "fastapi2.py\n",
      "fastformer.json\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_cluster_0_full_balanced_1_epoch.h5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.json\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_0_full_balanced_1_epoch.weights.h5\n",
      "fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      "fastformer_model.py\n",
      "gdrive.py\n",
      "models\n",
      "models.py\n",
      "my_log.py\n",
      "recommender.py\n",
      "requirements.txt\n",
      "results\n",
      "results.csv\n",
      "stage1_candidates.csv\n",
      "test_recommender.ipynb\n",
      "test_recommender.py\n",
      "tfidf_clicked_articles.csv\n",
      "tokenizer.pkl\n",
      "upload_to_hf.py\n",
      "user_category_profiles.pkl\n",
      "utils copy.py\n",
      "utils.py\n",
      "__pycache__\n",
      "2.18.0\n",
      "3.8.0\n",
      "\n",
      "Loading model for Cluster 2 from fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      ".cache\n",
      ".ipynb_checkpoints\n",
      ".Trash-0\n",
      "backend copy 2.py\n",
      "backend copy.py\n",
      "backend-flask-unused.py\n",
      "backend.py\n",
      "data\n",
      "dataset\n",
      "detailed_log.log\n",
      "Dockerfile\n",
      "downloads\n",
      "experiment_results.csv\n",
      "fastapi copy.py\n",
      "fastapi2.py\n",
      "fastformer.json\n",
      "fastformer_clusters.ipynb\n",
      "fastformer_cluster_0_full_balanced_1_epoch.h5\n",
      "fastformer_cluster_0_full_balanced_1_epoch.json\n",
      "fastformer_cluster_0_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_0_full_balanced_1_epoch.weights.h5\n",
      "fastformer_cluster_1_full_balanced_1_epoch.keras\n",
      "fastformer_cluster_2_full_balanced_1_epoch.keras\n",
      "fastformer_model.py\n",
      "gdrive.py\n",
      "models\n",
      "models.py\n",
      "my_log.py\n",
      "recommender.py\n",
      "requirements.txt\n",
      "results\n",
      "results.csv\n",
      "stage1_candidates.csv\n",
      "test_recommender.ipynb\n",
      "test_recommender.py\n",
      "tfidf_clicked_articles.csv\n",
      "tokenizer.pkl\n",
      "upload_to_hf.py\n",
      "user_category_profiles.pkl\n",
      "utils copy.py\n",
      "utils.py\n",
      "__pycache__\n",
      "2.18.0\n",
      "3.8.0\n",
      "Returning models list\n",
      "{0: <Functional name=functional, built=True>, 1: <Functional name=functional_1, built=True>, 2: <Functional name=functional_2, built=True>}\n",
      "Selected Reference Dates: ['2019-11-09T00:00:00Z', '2019-11-11T00:00:00Z', '2019-11-14T00:00:00Z']\n",
      "Test User IDs: ['U142719']\n",
      "current_date:2019-11-09 00:00:00+00:00\n",
      "Date range of behaviors: 2019-11-09 00:00:00 to 2019-11-14 23:59:59\n",
      "Date\n",
      "2019-11-09    192552\n",
      "2019-11-10    212343\n",
      "2019-11-11    464467\n",
      "2019-11-12    478375\n",
      "2019-11-13    453494\n",
      "2019-11-14    431517\n",
      "Name: count, dtype: int64\n",
      "cutoff_time:2019-11-08T00:00:00.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/utils.py:565: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  cutoff_time = np.datetime64(current_date - timedelta(hours=candidate_timeframe_hours))\n",
      "/app/utils.py:567: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(current_date)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent_behaviors:        ImpressionID   UserID       Time  \\\n",
      "472830        472831  U403465 2019-11-09   \n",
      "\n",
      "                                              HistoryText  \\\n",
      "472830  N59850 N104930 N68866 N82374 N123325 N127916 N...   \n",
      "\n",
      "                                              Impressions  \\\n",
      "472830  N92613-0 N17456-0 N67369-0 N31486-0 N76810-0 N...   \n",
      "\n",
      "                                        HistoryCategories        Date  \n",
      "472830  [news, news, tv, news, tv, news, news, news, n...  2019-11-09  \n",
      "Cutoff date (current_date - 24 hours): 2019-11-08T00:00:00.000000\n",
      "history_text:\n",
      "history_ids:[]\n",
      "TF-IDF similarity distribution plotted and saved as 'tfidf_similarity_distribution.png'.\n",
      "For user:U142719, row13833:N33037-0 N60032-0 N96373-0 N119637-0 N25037-0 N22659-0 N27251-0 N47257-0 N21819-0 N100900-0 N101119-0 N15137-0 N99484-0 N22597-0 N44558-0 N74438-0 N107637-0 N53225-0 N65552-0 N19455-0 N75391-1 N39784-0 N79094-0 N94356-0 N93674-0 N92699-0 N84137-0 N21883-0 N11682-0 N88148-0 N3075-0 N8719-0 N93643-0 N56390-0 N98478-0 N9720-0 N71368-0 N99498-0 N106539-0 N122726-0 N60829-0 N24798-0 N12586-0 N114546-0 N39197-0 N83421-0 N85266-0 N76489-0 N90822-0 N58417-0 N81064-0 N28925-0 N93411-0 N67068-0 N17575-0 N70822-0 N123077-0 N55792-0 N95135-0 N77310-0 N1928-0 N91757-0 N115772-0 N100343-0 N102394-0 N58258-0 N79081-0 N12453-0 N122819-0 N116064-0 N85986-0 N11296-0 N91892-0\n",
      "For user:U142719, row666425:N67937-0 N84720-0 N65446-0 N51569-0 N65017-0 N35236-0 N100456-0 N110627-0 N106659-0 N104161-0 N17475-0 N1923-0 N42649-0 N880-0 N46223-0 N97912-0 N80784-0 N16321-0 N20871-0 N102499-0 N90184-0 N56873-0 N34172-0 N92300-0 N84430-0 N51163-0 N92199-0 N76665-0 N29544-0 N16384-0 N105407-0 N102458-0 N91865-0 N50175-0 N114449-1 N29441-0 N57001-0 N97460-1 N25814-1 N123968-0 N76209-0 N120147-0 N57497-0 N74682-0\n",
      "For user:U142719, row749027:N32419-0 N123683-0 N44077-0 N130076-0 N77503-0 N79817-1 N79480-0 N99184-0 N16161-0 N89112-0 N107472-0 N19635-0 N83707-0 N29544-0 N50175-0 N17475-0 N48841-0 N60268-0 N94108-0 N100425-0 N34424-0 N65446-0 N46716-0 N114057-0 N74401-0 N99964-0 N33901-0 N19834-0 N117698-0 N40795-0 N102304-0 N33539-0 N89701-0 N48205-0 N4360-0 N59288-0 N84706-0 N73295-0 N95341-0 N87236-0 N49048-0 N103810-0 N102426-0 N4371-0 N103133-0 N118623-0 N880-0 N80770-0 N4384-0 N28930-0 N20250-0 N64238-0 N1923-0 N102845-0 N30955-0 N97743-0 N33378-0\n",
      "For user:U142719, row782902:N15549-0 N75646-0 N104665-0 N67937-0 N100738-0 N68624-0 N88329-0 N14675-0 N86258-1 N70883-0 N102846-0 N38861-0 N40625-0 N94999-0 N76189-0 N118623-0 N91238-0 N122944-0 N25814-0 N35236-0 N87146-0 N78508-1 N48841-0 N2297-0 N55761-0 N5496-0 N51163-0 N104990-0 N83707-0 N64041-0 N16716-0 N45782-0 N3623-0 N64785-0 N103810-0 N33539-0 N51307-0 N18761-1 N66929-0 N40795-0 N22627-0\n",
      "For user:U142719, row837890:N109749-0 N38737-0 N37105-0 N92077-0 N115958-0 N4858-1 N116501-0 N117508-0 N99362-1 N77310-0 N7299-0 N14509-0 N116064-0 N27282-0 N53271-0 N123626-0 N59654-0 N39-0 N78206-0 N54671-0 N73137-0 N107695-0 N54453-0 N87836-0 N100547-0 N12975-0 N61407-0 N38813-0 N351-0 N110521-0 N97946-0 N26404-0 N120919-0 N86208-1 N84137-0 N123362-1 N58992-0 N43955-0 N116736-0 N37025-0 N60110-0 N5032-0 N22393-0 N92952-0 N3987-0 N92463-0 N13322-0 N45124-1 N81936-0 N42296-0 N27703-0\n",
      "For user:U142719, row1619279:N104665-0 N68624-0 N50175-0 N88329-0 N51307-0 N55761-0 N40625-0 N91238-0 N104990-0 N45782-0 N67937-0 N75646-0 N14675-1 N51163-0 N64785-0 N4371-0 N94999-0 N102846-0 N70883-0 N122944-0 N3623-0 N16716-0 N100738-0 N2297-0 N83707-0\n",
      "For user:U142719, row1645368:N107637-0 N32154-1\n",
      "No clicked articles found among the candidate set.\n",
      "User U142719 history tensor shape: (1, 50, 30)\n",
      "Number of candidate articles selected: 0\n",
      "Stage 1 Candidate Count: 0\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "[save_stage_results] stage1_candidates results saved to results/stage1_candidates_results_U142719_20250323_235848.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/utils.py:326: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(after_time)\n",
      "/app/utils.py:326: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(after_time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user:U142719, row13833:N33037-0 N60032-0 N96373-0 N119637-0 N25037-0 N22659-0 N27251-0 N47257-0 N21819-0 N100900-0 N101119-0 N15137-0 N99484-0 N22597-0 N44558-0 N74438-0 N107637-0 N53225-0 N65552-0 N19455-0 N75391-1 N39784-0 N79094-0 N94356-0 N93674-0 N92699-0 N84137-0 N21883-0 N11682-0 N88148-0 N3075-0 N8719-0 N93643-0 N56390-0 N98478-0 N9720-0 N71368-0 N99498-0 N106539-0 N122726-0 N60829-0 N24798-0 N12586-0 N114546-0 N39197-0 N83421-0 N85266-0 N76489-0 N90822-0 N58417-0 N81064-0 N28925-0 N93411-0 N67068-0 N17575-0 N70822-0 N123077-0 N55792-0 N95135-0 N77310-0 N1928-0 N91757-0 N115772-0 N100343-0 N102394-0 N58258-0 N79081-0 N12453-0 N122819-0 N116064-0 N85986-0 N11296-0 N91892-0\n",
      "For user:U142719, row666425:N67937-0 N84720-0 N65446-0 N51569-0 N65017-0 N35236-0 N100456-0 N110627-0 N106659-0 N104161-0 N17475-0 N1923-0 N42649-0 N880-0 N46223-0 N97912-0 N80784-0 N16321-0 N20871-0 N102499-0 N90184-0 N56873-0 N34172-0 N92300-0 N84430-0 N51163-0 N92199-0 N76665-0 N29544-0 N16384-0 N105407-0 N102458-0 N91865-0 N50175-0 N114449-1 N29441-0 N57001-0 N97460-1 N25814-1 N123968-0 N76209-0 N120147-0 N57497-0 N74682-0\n",
      "For user:U142719, row749027:N32419-0 N123683-0 N44077-0 N130076-0 N77503-0 N79817-1 N79480-0 N99184-0 N16161-0 N89112-0 N107472-0 N19635-0 N83707-0 N29544-0 N50175-0 N17475-0 N48841-0 N60268-0 N94108-0 N100425-0 N34424-0 N65446-0 N46716-0 N114057-0 N74401-0 N99964-0 N33901-0 N19834-0 N117698-0 N40795-0 N102304-0 N33539-0 N89701-0 N48205-0 N4360-0 N59288-0 N84706-0 N73295-0 N95341-0 N87236-0 N49048-0 N103810-0 N102426-0 N4371-0 N103133-0 N118623-0 N880-0 N80770-0 N4384-0 N28930-0 N20250-0 N64238-0 N1923-0 N102845-0 N30955-0 N97743-0 N33378-0\n",
      "For user:U142719, row782902:N15549-0 N75646-0 N104665-0 N67937-0 N100738-0 N68624-0 N88329-0 N14675-0 N86258-1 N70883-0 N102846-0 N38861-0 N40625-0 N94999-0 N76189-0 N118623-0 N91238-0 N122944-0 N25814-0 N35236-0 N87146-0 N78508-1 N48841-0 N2297-0 N55761-0 N5496-0 N51163-0 N104990-0 N83707-0 N64041-0 N16716-0 N45782-0 N3623-0 N64785-0 N103810-0 N33539-0 N51307-0 N18761-1 N66929-0 N40795-0 N22627-0\n",
      "For user:U142719, row837890:N109749-0 N38737-0 N37105-0 N92077-0 N115958-0 N4858-1 N116501-0 N117508-0 N99362-1 N77310-0 N7299-0 N14509-0 N116064-0 N27282-0 N53271-0 N123626-0 N59654-0 N39-0 N78206-0 N54671-0 N73137-0 N107695-0 N54453-0 N87836-0 N100547-0 N12975-0 N61407-0 N38813-0 N351-0 N110521-0 N97946-0 N26404-0 N120919-0 N86208-1 N84137-0 N123362-1 N58992-0 N43955-0 N116736-0 N37025-0 N60110-0 N5032-0 N22393-0 N92952-0 N3987-0 N92463-0 N13322-0 N45124-1 N81936-0 N42296-0 N27703-0\n",
      "For user:U142719, row1619279:N104665-0 N68624-0 N50175-0 N88329-0 N51307-0 N55761-0 N40625-0 N91238-0 N104990-0 N45782-0 N67937-0 N75646-0 N14675-1 N51163-0 N64785-0 N4371-0 N94999-0 N102846-0 N70883-0 N122944-0 N3623-0 N16716-0 N100738-0 N2297-0 N83707-0\n",
      "For user:U142719, row1645368:N107637-0 N32154-1\n",
      "[save_stage_results] stage1_coverage results saved to results/stage1_coverage_results_U142719_20250323_235848.csv\n",
      "Ground-truth coverage: 0 out of 15 future clicked articles in candidate set.\n",
      "bagging done\n",
      "candidate_scores:[]\n",
      "candidate_scores:[]\n",
      "Error processing user U142719 with ref_date 2019-11-09T00:00:00Z: zero-size array to reduction operation minimum which has no identity\n",
      "current_date:2019-11-11 00:00:00+00:00\n",
      "Date range of behaviors: 2019-11-09 00:00:00 to 2019-11-14 23:59:59\n",
      "Date\n",
      "2019-11-09    192552\n",
      "2019-11-10    212343\n",
      "2019-11-11    464467\n",
      "2019-11-12    478375\n",
      "2019-11-13    453494\n",
      "2019-11-14    431517\n",
      "Name: count, dtype: int64\n",
      "cutoff_time:2019-11-10T00:00:00.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/utils.py:565: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  cutoff_time = np.datetime64(current_date - timedelta(hours=candidate_timeframe_hours))\n",
      "/app/utils.py:567: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(current_date)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recent_behaviors:         ImpressionID   UserID                Time  \\\n",
      "0                   1   U87243 2019-11-10 11:30:54   \n",
      "9                  10  U290933 2019-11-10 11:54:34   \n",
      "45                 46  U595088 2019-11-10 18:26:21   \n",
      "56                 57  U184159 2019-11-10 09:57:00   \n",
      "88                 89  U503349 2019-11-10 07:32:53   \n",
      "...               ...      ...                 ...   \n",
      "2232692       2232693  U248404 2019-11-10 16:46:31   \n",
      "2232695       2232696  U670414 2019-11-10 19:23:33   \n",
      "2232707       2232708  U557401 2019-11-10 10:47:01   \n",
      "2232730       2232731  U132053 2019-11-10 17:47:08   \n",
      "2232736       2232737  U215047 2019-11-10 06:16:42   \n",
      "\n",
      "                                               HistoryText  \\\n",
      "0        N8668 N39081 N65259 N79529 N73408 N43615 N2937...   \n",
      "9        N14678 N71340 N65259 N92085 N31043 N70385 N123...   \n",
      "45                     N60457 N100033 N84031 N97971 N19175   \n",
      "56                                   N126052 N54360 N51166   \n",
      "88       N35249 N20138 N53012 N28636 N81899 N81937 N224...   \n",
      "...                                                    ...   \n",
      "2232692  N97313 N90949 N104904 N17424 N18787 N129836 N5...   \n",
      "2232695  N63576 N21673 N116057 N37155 N16417 N112933 N1...   \n",
      "2232707  N7487 N44955 N105630 N49404 N40229 N1277 N6432...   \n",
      "2232730  N84419 N71340 N4857 N26421 N115826 N129128 N15...   \n",
      "2232736                                                      \n",
      "\n",
      "                                               Impressions  \\\n",
      "0        N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...   \n",
      "9        N92691-0 N10654-0 N107542-0 N14509-0 N63262-0 ...   \n",
      "45       N29486-0 N109605-0 N68098-0 N99844-0 N93955-1 ...   \n",
      "56       N18478-0 N40282-0 N2591-0 N64730-0 N78206-0 N9...   \n",
      "88       N52428-0 N26368-0 N93934-0 N54460-0 N93337-0 N...   \n",
      "...                                                    ...   \n",
      "2232692  N29948-0 N29486-0 N81321-0 N37338-0 N73825-0 N...   \n",
      "2232695  N40064-0 N77991-0 N111291-0 N51158-0 N37379-0 ...   \n",
      "2232707  N94157-0 N31174-0 N71090-0 N18478-0 N78206-0 N...   \n",
      "2232730                                   N3664-1 N16485-0   \n",
      "2232736  N29852-0 N7578-0 N78867-0 N104224-0 N84137-0 N...   \n",
      "\n",
      "                                         HistoryCategories        Date  \n",
      "0        [tv, news, music, health, music, news, lifesty...  2019-11-10  \n",
      "9        [sports, sports, music, health, news, news, sp...  2019-11-10  \n",
      "45                    [lifestyle, news, music, news, news]  2019-11-10  \n",
      "56                            [sports, news, foodanddrink]  2019-11-10  \n",
      "88       [finance, news, autos, autos, sports, news, fi...  2019-11-10  \n",
      "...                                                    ...         ...  \n",
      "2232692  [music, video, news, news, news, news, music, ...  2019-11-10  \n",
      "2232695  [sports, sports, sports, sports, sports, sport...  2019-11-10  \n",
      "2232707  [travel, news, sports, sports, health, foodand...  2019-11-10  \n",
      "2232730  [news, sports, news, news, autos, travel, tv, ...  2019-11-10  \n",
      "2232736                                                 []  2019-11-10  \n",
      "\n",
      "[212343 rows x 7 columns]\n",
      "Cutoff date (current_date - 24 hours): 2019-11-10T00:00:00.000000\n",
      "history_text:\n",
      "history_ids:[]\n",
      "TF-IDF similarity distribution plotted and saved as 'tfidf_similarity_distribution.png'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/utils.py:326: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(after_time)\n",
      "/app/utils.py:326: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(after_time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user:U142719, row13833:N33037-0 N60032-0 N96373-0 N119637-0 N25037-0 N22659-0 N27251-0 N47257-0 N21819-0 N100900-0 N101119-0 N15137-0 N99484-0 N22597-0 N44558-0 N74438-0 N107637-0 N53225-0 N65552-0 N19455-0 N75391-1 N39784-0 N79094-0 N94356-0 N93674-0 N92699-0 N84137-0 N21883-0 N11682-0 N88148-0 N3075-0 N8719-0 N93643-0 N56390-0 N98478-0 N9720-0 N71368-0 N99498-0 N106539-0 N122726-0 N60829-0 N24798-0 N12586-0 N114546-0 N39197-0 N83421-0 N85266-0 N76489-0 N90822-0 N58417-0 N81064-0 N28925-0 N93411-0 N67068-0 N17575-0 N70822-0 N123077-0 N55792-0 N95135-0 N77310-0 N1928-0 N91757-0 N115772-0 N100343-0 N102394-0 N58258-0 N79081-0 N12453-0 N122819-0 N116064-0 N85986-0 N11296-0 N91892-0\n",
      "For user:U142719, row666425:N67937-0 N84720-0 N65446-0 N51569-0 N65017-0 N35236-0 N100456-0 N110627-0 N106659-0 N104161-0 N17475-0 N1923-0 N42649-0 N880-0 N46223-0 N97912-0 N80784-0 N16321-0 N20871-0 N102499-0 N90184-0 N56873-0 N34172-0 N92300-0 N84430-0 N51163-0 N92199-0 N76665-0 N29544-0 N16384-0 N105407-0 N102458-0 N91865-0 N50175-0 N114449-1 N29441-0 N57001-0 N97460-1 N25814-1 N123968-0 N76209-0 N120147-0 N57497-0 N74682-0\n",
      "For user:U142719, row749027:N32419-0 N123683-0 N44077-0 N130076-0 N77503-0 N79817-1 N79480-0 N99184-0 N16161-0 N89112-0 N107472-0 N19635-0 N83707-0 N29544-0 N50175-0 N17475-0 N48841-0 N60268-0 N94108-0 N100425-0 N34424-0 N65446-0 N46716-0 N114057-0 N74401-0 N99964-0 N33901-0 N19834-0 N117698-0 N40795-0 N102304-0 N33539-0 N89701-0 N48205-0 N4360-0 N59288-0 N84706-0 N73295-0 N95341-0 N87236-0 N49048-0 N103810-0 N102426-0 N4371-0 N103133-0 N118623-0 N880-0 N80770-0 N4384-0 N28930-0 N20250-0 N64238-0 N1923-0 N102845-0 N30955-0 N97743-0 N33378-0\n",
      "For user:U142719, row782902:N15549-0 N75646-0 N104665-0 N67937-0 N100738-0 N68624-0 N88329-0 N14675-0 N86258-1 N70883-0 N102846-0 N38861-0 N40625-0 N94999-0 N76189-0 N118623-0 N91238-0 N122944-0 N25814-0 N35236-0 N87146-0 N78508-1 N48841-0 N2297-0 N55761-0 N5496-0 N51163-0 N104990-0 N83707-0 N64041-0 N16716-0 N45782-0 N3623-0 N64785-0 N103810-0 N33539-0 N51307-0 N18761-1 N66929-0 N40795-0 N22627-0\n",
      "For user:U142719, row1619279:N104665-0 N68624-0 N50175-0 N88329-0 N51307-0 N55761-0 N40625-0 N91238-0 N104990-0 N45782-0 N67937-0 N75646-0 N14675-1 N51163-0 N64785-0 N4371-0 N94999-0 N102846-0 N70883-0 N122944-0 N3623-0 N16716-0 N100738-0 N2297-0 N83707-0\n",
      "For user:U142719, row1645368:N107637-0 N32154-1\n",
      "No clicked articles found among the candidate set.\n",
      "User U142719 history tensor shape: (1, 50, 30)\n",
      "Number of candidate articles selected: 0\n",
      "Stage 1 Candidate Count: 0\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "[save_stage_results] stage1_candidates results saved to results/stage1_candidates_results_U142719_20250323_235854.csv\n",
      "For user:U142719, row13833:N33037-0 N60032-0 N96373-0 N119637-0 N25037-0 N22659-0 N27251-0 N47257-0 N21819-0 N100900-0 N101119-0 N15137-0 N99484-0 N22597-0 N44558-0 N74438-0 N107637-0 N53225-0 N65552-0 N19455-0 N75391-1 N39784-0 N79094-0 N94356-0 N93674-0 N92699-0 N84137-0 N21883-0 N11682-0 N88148-0 N3075-0 N8719-0 N93643-0 N56390-0 N98478-0 N9720-0 N71368-0 N99498-0 N106539-0 N122726-0 N60829-0 N24798-0 N12586-0 N114546-0 N39197-0 N83421-0 N85266-0 N76489-0 N90822-0 N58417-0 N81064-0 N28925-0 N93411-0 N67068-0 N17575-0 N70822-0 N123077-0 N55792-0 N95135-0 N77310-0 N1928-0 N91757-0 N115772-0 N100343-0 N102394-0 N58258-0 N79081-0 N12453-0 N122819-0 N116064-0 N85986-0 N11296-0 N91892-0\n",
      "For user:U142719, row666425:N67937-0 N84720-0 N65446-0 N51569-0 N65017-0 N35236-0 N100456-0 N110627-0 N106659-0 N104161-0 N17475-0 N1923-0 N42649-0 N880-0 N46223-0 N97912-0 N80784-0 N16321-0 N20871-0 N102499-0 N90184-0 N56873-0 N34172-0 N92300-0 N84430-0 N51163-0 N92199-0 N76665-0 N29544-0 N16384-0 N105407-0 N102458-0 N91865-0 N50175-0 N114449-1 N29441-0 N57001-0 N97460-1 N25814-1 N123968-0 N76209-0 N120147-0 N57497-0 N74682-0\n",
      "For user:U142719, row749027:N32419-0 N123683-0 N44077-0 N130076-0 N77503-0 N79817-1 N79480-0 N99184-0 N16161-0 N89112-0 N107472-0 N19635-0 N83707-0 N29544-0 N50175-0 N17475-0 N48841-0 N60268-0 N94108-0 N100425-0 N34424-0 N65446-0 N46716-0 N114057-0 N74401-0 N99964-0 N33901-0 N19834-0 N117698-0 N40795-0 N102304-0 N33539-0 N89701-0 N48205-0 N4360-0 N59288-0 N84706-0 N73295-0 N95341-0 N87236-0 N49048-0 N103810-0 N102426-0 N4371-0 N103133-0 N118623-0 N880-0 N80770-0 N4384-0 N28930-0 N20250-0 N64238-0 N1923-0 N102845-0 N30955-0 N97743-0 N33378-0\n",
      "For user:U142719, row782902:N15549-0 N75646-0 N104665-0 N67937-0 N100738-0 N68624-0 N88329-0 N14675-0 N86258-1 N70883-0 N102846-0 N38861-0 N40625-0 N94999-0 N76189-0 N118623-0 N91238-0 N122944-0 N25814-0 N35236-0 N87146-0 N78508-1 N48841-0 N2297-0 N55761-0 N5496-0 N51163-0 N104990-0 N83707-0 N64041-0 N16716-0 N45782-0 N3623-0 N64785-0 N103810-0 N33539-0 N51307-0 N18761-1 N66929-0 N40795-0 N22627-0\n",
      "For user:U142719, row1619279:N104665-0 N68624-0 N50175-0 N88329-0 N51307-0 N55761-0 N40625-0 N91238-0 N104990-0 N45782-0 N67937-0 N75646-0 N14675-1 N51163-0 N64785-0 N4371-0 N94999-0 N102846-0 N70883-0 N122944-0 N3623-0 N16716-0 N100738-0 N2297-0 N83707-0\n",
      "For user:U142719, row1645368:N107637-0 N32154-1\n",
      "[save_stage_results] stage1_coverage results saved to results/stage1_coverage_results_U142719_20250323_235854.csv\n",
      "Ground-truth coverage: 0 out of 10 future clicked articles in candidate set.\n",
      "bagging done\n",
      "candidate_scores:[]\n",
      "candidate_scores:[]\n",
      "Error processing user U142719 with ref_date 2019-11-11T00:00:00Z: zero-size array to reduction operation minimum which has no identity\n",
      "current_date:2019-11-14 00:00:00+00:00\n",
      "Date range of behaviors: 2019-11-09 00:00:00 to 2019-11-14 23:59:59\n",
      "Date\n",
      "2019-11-09    192552\n",
      "2019-11-10    212343\n",
      "2019-11-11    464467\n",
      "2019-11-12    478375\n",
      "2019-11-13    453494\n",
      "2019-11-14    431517\n",
      "Name: count, dtype: int64\n",
      "cutoff_time:2019-11-13T00:00:00.000000\n",
      "recent_behaviors:         ImpressionID   UserID                Time  \\\n",
      "2                   3  U532401 2019-11-13 11:23:03   \n",
      "6                   7  U687515 2019-11-13 05:31:06   \n",
      "12                 13   U86679 2019-11-13 15:51:47   \n",
      "25                 26   U90382 2019-11-13 13:04:57   \n",
      "35                 36  U569010 2019-11-13 08:41:58   \n",
      "...               ...      ...                 ...   \n",
      "2232728       2232729   U65355 2019-11-13 19:12:22   \n",
      "2232737       2232738  U424578 2019-11-13 10:44:02   \n",
      "2232743       2232744  U316192 2019-11-13 18:50:02   \n",
      "2232745       2232746  U151246 2019-11-13 12:42:51   \n",
      "2232747       2232748  U500938 2019-11-13 20:10:45   \n",
      "\n",
      "                                               HistoryText  \\\n",
      "2        N128643 N87446 N122948 N9375 N82348 N129412 N5...   \n",
      "6                             N91810 N96438 N104027 N53650   \n",
      "12       N15232 N112192 N1277 N67120 N59752 N8771 N1822...   \n",
      "25       N128965 N72571 N3435 N39384 N89398 N82348 N823...   \n",
      "35       N104737 N71977 N3285 N5992 N54978 N114571 N915...   \n",
      "...                                                    ...   \n",
      "2232728                       N73763 N92775 N78719 N117401   \n",
      "2232737  N65123 N63858 N2661 N40628 N98238 N98238 N9892...   \n",
      "2232743  N122359 N37069 N95876 N28787 N73408 N11266 N61321   \n",
      "2232745                                      N27587 N49668   \n",
      "2232747  N13311 N73573 N36246 N47118 N71728 N105480 N61...   \n",
      "\n",
      "                                               Impressions  \\\n",
      "2                    N103852-0 N53474-0 N127836-0 N47925-1   \n",
      "6        N12681-0 N10802-0 N93856-0 N96729-0 N46415-0 N...   \n",
      "12       N95525-0 N4504-0 N75618-0 N37178-0 N80994-0 N1...   \n",
      "25       N100261-0 N76677-0 N53474-0 N5287-0 N123968-0 ...   \n",
      "35       N93856-0 N46415-0 N95525-0 N96729-0 N65313-0 N...   \n",
      "...                                                    ...   \n",
      "2232728  N75618-0 N13161-0 N101552-0 N37178-0 N24701-0 ...   \n",
      "2232737  N88472-0 N106659-0 N51686-0 N10285-0 N127836-0...   \n",
      "2232743      N113723-0 N123683-1 N5287-0 N76677-0 N53474-0   \n",
      "2232745  N39887-1 N22811-0 N110709-1 N1923-0 N24001-1 N...   \n",
      "2232747  N24701-0 N13161-0 N39403-0 N40310-0 N5287-0 N1...   \n",
      "\n",
      "                                         HistoryCategories        Date  \n",
      "2        [tv, movies, video, tv, news, music, lifestyle...  2019-11-13  \n",
      "6                   [music, lifestyle, finance, lifestyle]  2019-11-13  \n",
      "12       [lifestyle, tv, foodanddrink, foodanddrink, li...  2019-11-13  \n",
      "25       [tv, sports, news, news, news, news, news, vid...  2019-11-13  \n",
      "35       [movies, sports, movies, news, news, movies, l...  2019-11-13  \n",
      "...                                                    ...         ...  \n",
      "2232728           [news, health, lifestyle, entertainment]  2019-11-13  \n",
      "2232737  [foodanddrink, sports, news, lifestyle, news, ...  2019-11-13  \n",
      "2232743      [movies, news, tv, tv, music, finance, video]  2019-11-13  \n",
      "2232745                                         [news, tv]  2019-11-13  \n",
      "2232747  [news, finance, news, news, travel, news, news...  2019-11-13  \n",
      "\n",
      "[453497 rows x 7 columns]\n",
      "Cutoff date (current_date - 24 hours): 2019-11-13T00:00:00.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/utils.py:565: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  cutoff_time = np.datetime64(current_date - timedelta(hours=candidate_timeframe_hours))\n",
      "/app/utils.py:567: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(current_date)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history_text:\n",
      "history_ids:[]\n",
      "TF-IDF similarity distribution plotted and saved as 'tfidf_similarity_distribution.png'.\n",
      "For user:U142719, row666425:N67937-0 N84720-0 N65446-0 N51569-0 N65017-0 N35236-0 N100456-0 N110627-0 N106659-0 N104161-0 N17475-0 N1923-0 N42649-0 N880-0 N46223-0 N97912-0 N80784-0 N16321-0 N20871-0 N102499-0 N90184-0 N56873-0 N34172-0 N92300-0 N84430-0 N51163-0 N92199-0 N76665-0 N29544-0 N16384-0 N105407-0 N102458-0 N91865-0 N50175-0 N114449-1 N29441-0 N57001-0 N97460-1 N25814-1 N123968-0 N76209-0 N120147-0 N57497-0 N74682-0\n",
      "For user:U142719, row749027:N32419-0 N123683-0 N44077-0 N130076-0 N77503-0 N79817-1 N79480-0 N99184-0 N16161-0 N89112-0 N107472-0 N19635-0 N83707-0 N29544-0 N50175-0 N17475-0 N48841-0 N60268-0 N94108-0 N100425-0 N34424-0 N65446-0 N46716-0 N114057-0 N74401-0 N99964-0 N33901-0 N19834-0 N117698-0 N40795-0 N102304-0 N33539-0 N89701-0 N48205-0 N4360-0 N59288-0 N84706-0 N73295-0 N95341-0 N87236-0 N49048-0 N103810-0 N102426-0 N4371-0 N103133-0 N118623-0 N880-0 N80770-0 N4384-0 N28930-0 N20250-0 N64238-0 N1923-0 N102845-0 N30955-0 N97743-0 N33378-0\n",
      "For user:U142719, row782902:N15549-0 N75646-0 N104665-0 N67937-0 N100738-0 N68624-0 N88329-0 N14675-0 N86258-1 N70883-0 N102846-0 N38861-0 N40625-0 N94999-0 N76189-0 N118623-0 N91238-0 N122944-0 N25814-0 N35236-0 N87146-0 N78508-1 N48841-0 N2297-0 N55761-0 N5496-0 N51163-0 N104990-0 N83707-0 N64041-0 N16716-0 N45782-0 N3623-0 N64785-0 N103810-0 N33539-0 N51307-0 N18761-1 N66929-0 N40795-0 N22627-0\n",
      "For user:U142719, row1619279:N104665-0 N68624-0 N50175-0 N88329-0 N51307-0 N55761-0 N40625-0 N91238-0 N104990-0 N45782-0 N67937-0 N75646-0 N14675-1 N51163-0 N64785-0 N4371-0 N94999-0 N102846-0 N70883-0 N122944-0 N3623-0 N16716-0 N100738-0 N2297-0 N83707-0\n",
      "No clicked articles found among the candidate set.\n",
      "User U142719 history tensor shape: (1, 50, 30)\n",
      "Number of candidate articles selected: 0\n",
      "Stage 1 Candidate Count: 0\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "[save_stage_results] stage1_candidates results saved to results/stage1_candidates_results_U142719_20250323_235906.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/utils.py:326: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(after_time)\n",
      "/app/utils.py:326: UserWarning: no explicit representation of timezones available for np.datetime64\n",
      "  ref_dt64 = np.datetime64(after_time)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user:U142719, row666425:N67937-0 N84720-0 N65446-0 N51569-0 N65017-0 N35236-0 N100456-0 N110627-0 N106659-0 N104161-0 N17475-0 N1923-0 N42649-0 N880-0 N46223-0 N97912-0 N80784-0 N16321-0 N20871-0 N102499-0 N90184-0 N56873-0 N34172-0 N92300-0 N84430-0 N51163-0 N92199-0 N76665-0 N29544-0 N16384-0 N105407-0 N102458-0 N91865-0 N50175-0 N114449-1 N29441-0 N57001-0 N97460-1 N25814-1 N123968-0 N76209-0 N120147-0 N57497-0 N74682-0\n",
      "For user:U142719, row749027:N32419-0 N123683-0 N44077-0 N130076-0 N77503-0 N79817-1 N79480-0 N99184-0 N16161-0 N89112-0 N107472-0 N19635-0 N83707-0 N29544-0 N50175-0 N17475-0 N48841-0 N60268-0 N94108-0 N100425-0 N34424-0 N65446-0 N46716-0 N114057-0 N74401-0 N99964-0 N33901-0 N19834-0 N117698-0 N40795-0 N102304-0 N33539-0 N89701-0 N48205-0 N4360-0 N59288-0 N84706-0 N73295-0 N95341-0 N87236-0 N49048-0 N103810-0 N102426-0 N4371-0 N103133-0 N118623-0 N880-0 N80770-0 N4384-0 N28930-0 N20250-0 N64238-0 N1923-0 N102845-0 N30955-0 N97743-0 N33378-0\n",
      "For user:U142719, row782902:N15549-0 N75646-0 N104665-0 N67937-0 N100738-0 N68624-0 N88329-0 N14675-0 N86258-1 N70883-0 N102846-0 N38861-0 N40625-0 N94999-0 N76189-0 N118623-0 N91238-0 N122944-0 N25814-0 N35236-0 N87146-0 N78508-1 N48841-0 N2297-0 N55761-0 N5496-0 N51163-0 N104990-0 N83707-0 N64041-0 N16716-0 N45782-0 N3623-0 N64785-0 N103810-0 N33539-0 N51307-0 N18761-1 N66929-0 N40795-0 N22627-0\n",
      "For user:U142719, row1619279:N104665-0 N68624-0 N50175-0 N88329-0 N51307-0 N55761-0 N40625-0 N91238-0 N104990-0 N45782-0 N67937-0 N75646-0 N14675-1 N51163-0 N64785-0 N4371-0 N94999-0 N102846-0 N70883-0 N122944-0 N3623-0 N16716-0 N100738-0 N2297-0 N83707-0\n",
      "[save_stage_results] stage1_coverage results saved to results/stage1_coverage_results_U142719_20250323_235906.csv\n",
      "Ground-truth coverage: 0 out of 8 future clicked articles in candidate set.\n",
      "bagging done\n",
      "candidate_scores:[]\n",
      "candidate_scores:[]\n",
      "Error processing user U142719 with ref_date 2019-11-14T00:00:00Z: zero-size array to reduction operation minimum which has no identity\n",
      "Experiment results saved to 'experiment_results.csv'\n"
     ]
    }
   ],
   "source": [
    "from utils import get_models, run_experiments_modular\n",
    "models_dict, news_df, behaviors_df, tokenizer = get_models()\n",
    "    \n",
    "# Fit a TF-IDF vectorizer on the news combined text.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(news_df[\"CombinedText\"])\n",
    "\n",
    "results_df = run_experiments_modular(\n",
    "    behaviors_df, news_df, models_dict, tokenizer,\n",
    "    tfidf_vectorizer=tfidf_vectorizer,\n",
    "    max_candidates=-1, test_user_count=1, n_dates=3,\n",
    "    timeframe_hours=24*10, k=100, ensemble_method=\"bagging\",\n",
    "    min_tfidf_similarity=0.02\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "528cdd8c-a0d3-46bd-8f1a-88f79d6a2dd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2964736887.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfail here!!\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "fail here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from utils import get_models, run_experiments\n",
    "models_dict, news_df, behaviors_df, tokenizer = get_models()\n",
    "user_data = behaviors_df[behaviors_df['UserID'] == \"U379278\"]\n",
    "print(user_data[['Time', 'Impressions']])\n",
    "\n",
    "run_experiments(behaviors_df, models_dict, -1, 1, 5, 24*10, 20, filter_method=\"both\", min_tfidf_similarity=0.02)\n",
    "#def run_experiments(behaviors_df, models_dict, max_candidates=-1, test_user_count=1, n_dates=3, timeframe_hours=1, k=5, filter_method=\"both\", min_tfidf_similarity=0.02, tfidf_vectorizer=None):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5262f5c1-f3ee-4b24-b6fd-e4b9de6073ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.0, 1.0, 21)\n",
    "performance = []\n",
    "\n",
    "for thr in thresholds:\n",
    "    filtered_candidates = [score for score in candidate_similarities if score >= thr]\n",
    "    # Here, compute your chosen metric (e.g., F1 or Precision@K) using the filtered candidates.\n",
    "    metric_value = compute_metric(filtered_candidates, ground_truth_clicks)\n",
    "    performance.append(metric_value)\n",
    "\n",
    "plt.plot(thresholds, performance, marker='o')\n",
    "plt.xlabel(\"TF‑IDF Similarity Threshold\")\n",
    "plt.ylabel(\"Metric (e.g., F1‑score)\")\n",
    "plt.title(\"Threshold Tuning for Candidate Filtering\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "from utils import get_models  # Ensure these are in your PYTHONPATH\n",
    "from recommender import ensemble_bagging, ensemble_boosting, train_stacking_meta_model, ensemble_stacking, hybrid_ensemble, tokenize_input\n",
    "\n",
    "# For demonstration, we assume get_models() returns a dictionary of models for clusters 0, 1, 2, etc.\n",
    "print(\"Modules imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7c730-e9d6-4a9f-b541-9c779858a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "# Remap standalone keras modules to tensorflow.keras\n",
    "sys.modules[\"keras.preprocessing.text\"] = tf.keras.preprocessing.text\n",
    "sys.modules[\"keras.preprocessing.sequence\"] = tf.keras.preprocessing.sequence\n",
    "sys.modules[\"keras.utils\"] = tf.keras.utils\n",
    "\n",
    "news_file = \"news.tsv\"\n",
    "behaviors_file = \"behaviors.tsv\"\n",
    "data_dir = 'dataset/train/'  # Adjust path as necessary\n",
    "valid_data_dir = 'dataset/valid/'  # Adjust path as necessary\n",
    "news_path = os.path.join(data_dir, news_file)\n",
    "behaviors_path = os.path.join(data_dir, behaviors_file)\n",
    "\n",
    "# Set maximum lengths (should match your model settings)\n",
    "max_history_length = 50\n",
    "max_title_length = 30\n",
    "\n",
    "# Load the pre-saved tokenizer (assumes you already created and saved it)\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Load MIND test data (adjust file paths as necessary)\n",
    "# Assume news.tsv contains columns: NewsID, Category, SubCategory, Title, Abstract, URL, TitleEntities, AbstractEntities\n",
    "news_df = pd.read_csv(news_path, sep='\\t', \n",
    "                      names=['NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', 'URL', 'TitleEntities', 'AbstractEntities'])\n",
    "# Assume behaviors_test.tsv contains: ImpressionID, UserID, Time, HistoryText, Impressions\n",
    "behaviors_df = pd.read_csv(behaviors_path, sep='\\t', \n",
    "                           names=['ImpressionID', 'UserID', 'Time', 'HistoryText', 'Impressions'])\n",
    "\n",
    "# Create a dictionary mapping NewsID to Title (or CombinedText if available)\n",
    "news_dict = dict(zip(news_df['NewsID'], news_df['Title']))\n",
    "\n",
    "# Select one sample from the test behaviors\n",
    "sample = behaviors_df.iloc[0]\n",
    "\n",
    "# Process history: split the HistoryText (a space-separated string of NewsIDs)\n",
    "history_text = sample['HistoryText']\n",
    "history_ids = history_text.split() if pd.notna(history_text) else []\n",
    "\n",
    "# Retrieve the title for each news ID in the history (default to empty string if missing)\n",
    "history_titles = [news_dict.get(nid, \"\") for nid in history_ids]\n",
    "\n",
    "# Convert history titles to sequences using the tokenizer\n",
    "history_sequences = tokenizer.texts_to_sequences(history_titles)\n",
    "# Pad each sequence to max_title_length\n",
    "history_padded = pad_sequences(history_sequences, maxlen=max_title_length, \n",
    "                               padding='post', truncating='post', value=0)\n",
    "\n",
    "# Ensure the history has exactly max_history_length rows:\n",
    "if history_padded.shape[0] < max_history_length:\n",
    "    # Pre-pad with zeros if there are fewer history items\n",
    "    pad_rows = np.zeros((max_history_length - history_padded.shape[0], max_title_length), dtype=int)\n",
    "    history_padded = np.vstack([pad_rows, history_padded])\n",
    "else:\n",
    "    # If too many, take the last max_history_length items\n",
    "    history_padded = history_padded[-max_history_length:]\n",
    "\n",
    "# Process candidate: the \"Impressions\" column is a space-separated list like \"newsID-label newsID-label ...\"\n",
    "impressions = sample['Impressions']\n",
    "first_candidate = impressions.split()[0]  # take the first candidate\n",
    "candidate_news_id = first_candidate.split('-')[0]\n",
    "candidate_title = news_dict.get(candidate_news_id, \"\")\n",
    "candidate_sequence = tokenizer.texts_to_sequences([candidate_title])\n",
    "candidate_padded = pad_sequences(candidate_sequence, maxlen=max_title_length, \n",
    "                                 padding='post', truncating='post', value=0)[0]\n",
    "\n",
    "# Convert to TensorFlow tensors\n",
    "history_tensor = tf.convert_to_tensor([history_padded], dtype=tf.int32)  # shape: (1, max_history_length, max_title_length)\n",
    "candidate_tensor = tf.convert_to_tensor([candidate_padded], dtype=tf.int32)  # shape: (1, max_title_length)\n",
    "\n",
    "print(\"History tensor shape:\", history_tensor.shape)\n",
    "print(\"Candidate tensor shape:\", candidate_tensor.shape)\n",
    "\n",
    "# Load ensemble models using the get_models function\n",
    "print(\"Loading models...\")\n",
    "models_dict = get_models()\n",
    "print(\"Models loaded:\", models_dict.keys())\n",
    "\n",
    "# Test ensemble bagging\n",
    "bagging_pred = ensemble_bagging(history_tensor, candidate_tensor, models_dict)\n",
    "print(\"Ensemble Bagging Prediction:\", bagging_pred)\n",
    "\n",
    "# Test ensemble boosting with dummy error values\n",
    "dummy_errors = np.array([0.2, 0.15, 0.25])\n",
    "boosting_pred = ensemble_boosting(history_tensor, candidate_tensor, models_dict, dummy_errors)\n",
    "print(\"Ensemble Boosting Prediction:\", boosting_pred)\n",
    "\n",
    "# Test ensemble stacking with dummy training data\n",
    "X_train_dummy = np.array([\n",
    "    [0.80, 0.75, 0.85],\n",
    "    [0.55, 0.60, 0.50],\n",
    "    [0.30, 0.35, 0.25],\n",
    "    [0.20, 0.25, 0.15]\n",
    "])\n",
    "y_train_dummy = np.array([1, 0, 1, 0])\n",
    "meta_model = train_stacking_meta_model(X_train_dummy, y_train_dummy)\n",
    "stacking_pred = ensemble_stacking(history_tensor, candidate_tensor, models_dict, meta_model)\n",
    "print(\"Ensemble Stacking Prediction:\", stacking_pred)\n",
    "\n",
    "# Test hybrid ensemble\n",
    "hybrid_pred = hybrid_ensemble(history_tensor, candidate_tensor, models_dict, dummy_errors, meta_model)\n",
    "print(\"Hybrid Ensemble Prediction:\", hybrid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2e6a8",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "You can now develop and test your recommendation functions independently of the FastAPI backend. \n",
    "\n",
    "For further debugging, you might want to add additional print statements or assertions within your recommender functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
